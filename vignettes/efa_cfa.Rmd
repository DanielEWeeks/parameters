---
title: "Structural Models (EFA, CFA, SEM, ...)"
output: 
  github_document:
    toc: true
    fig_width: 10.08
    fig_height: 6
  rmarkdown::html_vignette:
    toc: true
    fig_width: 10.08
    fig_height: 6
tags: [r, parameters, efa, cfa, factor analysis, sem, fa, pca, how many factors, n factors]
vignette: >
  %\VignetteIndexEntry{Variable extraction (PCA, FA, ...)}
  \usepackage[utf8]{inputenc}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
bibliography: bibliography.bib
---

```{r message=FALSE, warning=FALSE, include=FALSE}
library(knitr)
options(knitr.kable.NA = '')
knitr::opts_chunk$set(comment=">")
options(digits=2)

set.seed(333)
```



## Exploratory Factor Analysis (EFA)

The difference between PCA and EFA can be quite hard to intuitively grasp as their output is very familiar. The idea is that PCA aims at extracting the most variance possible from all variables of the dataset, whereas EFA aims at creating consistent factors from the dataset without desperately trying to represent all the variables. 

This is why PCA is popular for feature reduction, as it will try to best represent the variance contained in the original data, minimizing the loss of information. On the other hand, EFA is usually in the context of exploring the latent dimensions that might be hidden in the observed variables, without necessary striving at representing the whole dataset.

To illustrate EFA, let us use the [International Personality Item Pool](ipip.ori.org) data available in the [ `psych`](https://www.personality-project.org/r/html/bfi.html) package. It includes 25 personality self report items. We will explore a factor structure made of 5 latent variables.

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(psych)
library(parameters)

data <- psych::bfi[, 1:25]  # Select only the 25 first columns corresponding to the items
data <- na.omit(data)  # remove missing values

# Fit an EFA
efa <- psych::fa(data, nfactors = 5) %>% 
  model_parameters(sort = TRUE, threshold = "max")
efa
```

As we can see, the 25 items nicely spread on the 5 latent factors which are, you guessed it, the famous **big 5**. Based on this model, we can now predict back the scores for each individual for these new variables:

```{r message=FALSE, warning=FALSE}
predict(efa, names = c("Neuroticism", "Conscientiousness", "Extraversion", "Agreeableness", "Opennness"))
```


# How many factors to retain in Factor Analysis (FA)


When running a **factor analysis (FA)**, one often needs to specify **how many components** (or latent variables) to retain or to extract. This decision is often motivated or supported by some statistical indices and procedures aiming at finding the optimal number of factors. 

Interestingly, a huge amount of methods exist to statistically adress this issue, giving sometimes very different results... Unfortunately, there is no consensus on **which method to use**, or which is the best.


## The Method Agreement procedure

The Method Agreement procedure, first implemented in the [`psycho`](https://neuropsychology.github.io/psycho.R/2018/05/24/n_factors.html) pacakge [@makowski2018psycho], proposes to rely on the consensus of methods, rather than on one method in particular.


This procedure can be easily used via the `n_factors()` function, re-implemented and improved in the [**parameters**](https://github.com/easystats/parameters) package. One can provide a dataframe, and the function will run a large number of routines and reutrn the optimal number of factors based on the higher consensus.  


```{r message=FALSE, warning=FALSE}
n <- n_factors(data)
n
```

Interestingly, the smallest nubmer of factors that most methods suggest is 6... Which is consistent whith the newer models of personality (e.g., HEXACO).

More details, as well as a summary table can be obtained as follows:

```{r message=FALSE, warning=FALSE}
as.data.frame(n)
summary(n)
```


A plot can also be obtained (the `see` package must be loaded):

```{r message=FALSE, warning=FALSE}
library(see)

plot(n) +
  theme_modern()
```


# References